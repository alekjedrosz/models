{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A decision tree implementation using the CART algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HOME = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Node = namedtuple('Node', ['threshold', 'feature_index', 'majority_class', 'left', 'right'])\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    \"\"\" A decision tree classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.n_classes = None\n",
    "        self.n_features = None\n",
    "        self.max_depth = None\n",
    "        self.root = None\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Assigns a class to each observation. \n",
    "        \n",
    "        :param X: A matrix of observations of shape (n_observations, n_features).\n",
    "        :returns: An array of predicted classes corresponding to each observation.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for observation in X:\n",
    "            node = self.root\n",
    "            while node.left is not None:\n",
    "                if observation[node.feature_index] <= node.threshold:\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "            predictions.append(node.majority_class)\n",
    "        return predictions\n",
    "        \n",
    "    def fit(self, X, y, max_depth=10):\n",
    "        \"\"\" Builds a tree based on the given observations.\n",
    "        \n",
    "        :param X: A matrix of observations of shape (n_observations, n_features).\n",
    "        :param y: A vector of output classes corresponding to the observations in ''X'', \n",
    "        of shape (n_observations,).\n",
    "        :param max_depth: The maximum depth of the tree.\n",
    "        \"\"\"\n",
    "        self.n_features = X.shape[1]\n",
    "        self.n_classes = np.max(y) + 1\n",
    "        self.max_depth = max_depth\n",
    "        self.root = self.build_tree(X, y, 0)\n",
    "        \n",
    "        \n",
    "    def build_tree(self, X, y, depth):\n",
    "        \"\"\" Recursively splits each node and builds the left and right subtrees\n",
    "        on a subset of observations, dictated by the feature and threshold returned\n",
    "        by ''self.best_node_split''.\n",
    "        \n",
    "        :param X: A matrix of observations, limited to the ones that satisfy the conditions\n",
    "        of the above nodes, of shape (n_observations, n_features).\n",
    "        :param y: A vector of output classes corresponding to the observations in ''X'', \n",
    "        of shape (n_observations,).\n",
    "        :param depth: The current depth of the tree.\n",
    "        \"\"\"\n",
    "        class_counts = np.array([np.sum(y==c) for c in range(self.n_classes)])\n",
    "        majority_class = np.argmax(class_counts)\n",
    "        best_feature, best_threshold = None, None\n",
    "        left, right = None, None\n",
    "        \n",
    "        if depth < self.max_depth:\n",
    "            best_feature, best_threshold = self.best_node_split(X, y)\n",
    "            if best_feature is not None:\n",
    "                left_mask = X[:, best_feature] < best_threshold\n",
    "                left = self.build_tree(X[left_mask, :], y[left_mask], depth+1)\n",
    "                right_mask = X[:, best_feature] > best_threshold\n",
    "                right = self.build_tree(X[right_mask, :], y[right_mask], depth+1)\n",
    "        \n",
    "        return Node(best_threshold, best_feature, majority_class, left, right)\n",
    "        \n",
    "    \n",
    "    def best_node_split(self, X, y):\n",
    "        \"\"\" Finds a feature and a threshold that leads to the smallest gini impurity\n",
    "        of the child nodes (weighted by the number of observations in each of the child\n",
    "        nodes). Considers every midpoint between two adjacent values (in sorted order) \n",
    "        of each feature as a possible split threshold.\n",
    "        \n",
    "        :param X: A matrix of observations to consider for the split, of shape \n",
    "        (n_observations, n_features).\n",
    "        :param y: A vector of output classes corresponding to the observations in ''X'', \n",
    "        of shape (n_observations,).\n",
    "        \"\"\"\n",
    "        n_observations = X.shape[0]\n",
    "        class_counts = np.array([np.sum(y==c) for c in range(self.n_classes)])\n",
    "        \n",
    "        # Parent's gini index\n",
    "        best_gini = 1 - np.sum((class_counts / n_observations) ** 2)\n",
    "        best_feature, best_threshold = None, None\n",
    "        \n",
    "        for feature in range(self.n_features):\n",
    "            # Sorting ''X'' and ''y'' in ascending order of the current feature\n",
    "            sorted_indices = np.argsort(X[:, feature])\n",
    "            sorted_observations = X[sorted_indices, feature]\n",
    "            sorted_classes = y[sorted_indices]\n",
    "            \n",
    "            # Starting with all observations larger than the threshold (in the right child node)\n",
    "            left_class_counts = np.array([0] * self.n_classes)\n",
    "            right_class_counts = class_counts.copy()\n",
    "            \n",
    "            # For every midpoint between two adjacent observations (after sorting)\n",
    "            for midpoint_id in range(1, n_observations):\n",
    "                # Observation class directly below the considered midpoint value\n",
    "                prev_observation_class = sorted_classes[midpoint_id - 1]\n",
    "                # Moving this observation to the left child node\n",
    "                left_class_counts[prev_observation_class] += 1\n",
    "                # And removing it from the right child node\n",
    "                right_class_counts[prev_observation_class] -= 1\n",
    "                # Nr. of observations in the left child is the enumerated midpoint index \n",
    "                n_observations_left = midpoint_id\n",
    "                # Nr. of observations in the right child is the rest of the observations\n",
    "                n_observations_right = n_observations - n_observations_left\n",
    "                \n",
    "                # Calculating gini index for both child nodes\n",
    "                gini_left = 1 - np.sum((left_class_counts / n_observations_left) ** 2)\n",
    "                gini_right = 1 - np.sum((right_class_counts / n_observations_right) ** 2)\n",
    "                # And their weighted average\n",
    "                gini = (1 / n_observations) * (n_observations_left * gini_left + n_observations_right * gini_right)\n",
    "                \n",
    "                # Skipping midpoints between observations with the same values of the current feature\n",
    "                if sorted_observations[midpoint_id] == sorted_observations[midpoint_id - 1]:\n",
    "                    continue\n",
    "                    \n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature\n",
    "                    # The threshold is an average of the two adjacent observations\n",
    "                    best_threshold = (sorted_observations[midpoint_id - 1] + sorted_observations[midpoint_id]) / 2\n",
    "                    \n",
    "        return best_feature, best_threshold   \n",
    "    \n",
    "    def print_tree(self):\n",
    "        \"\"\" Prints the tree to console.\n",
    "        \"\"\"\n",
    "        lines, _, _, _ = self._print_tree_aux(self.root)\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "\n",
    "    def _print_tree_aux(self, node):\n",
    "        \"\"\" Recursively creates a string representation of the tree. ''self.print_tree'' helper method. \n",
    "        :param node: Node from which to recursively begin creating the string representation.\n",
    "        :returns: A list of lines, the width, the height, and the horizontal coordinate of the root.\n",
    "        \"\"\"\n",
    "        if node.right is None and node.left is None:\n",
    "            line = f'c: {node.majority_class}'\n",
    "            width = len(line)\n",
    "            height = 1\n",
    "            middle = width // 2\n",
    "            return [line], width, height, middle\n",
    "        else:\n",
    "            left, n, p, x = self._print_tree_aux(node.left)\n",
    "            right, m, q, y = self._print_tree_aux(node.right)\n",
    "            s = f'f: {node.feature_index}, t: {node.threshold}'\n",
    "            u = len(s)\n",
    "            first_line = (x + 1) * ' ' + (n - x - 1) * '_' + s + y * '_' + (m - y) * ' '\n",
    "            second_line = x * ' ' + '/' + (n - x - 1 + u + y) * ' ' + '\\\\' + (m - y - 1) * ' '\n",
    "            if p < q:\n",
    "                left += [n * ' '] * (q - p)\n",
    "            elif q < p:\n",
    "                right += [m * ' '] * (p - q)\n",
    "            zipped_lines = zip(left, right)\n",
    "            lines = [first_line, second_line] + [a + u * ' ' + b for a, b in zipped_lines]\n",
    "            return lines, n + m + u, max(p, q) + 2, n + u // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.read_csv(os.path.join(DATA_HOME, 'iris.data'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_data.iloc[:, :-1].to_numpy()\n",
    "y = label_encoder.fit_transform(iris_data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _f: 2, t: 2.35___________________________________________                                            \n",
      "  /                                                         \\                                           \n",
      "c: 0                        __________________________f: 2, t: 4.95__________________________           \n",
      "                           /                                                                 \\          \n",
      "                    _f: 3, t: 1.65__________                                  _________f: 2, t: 5.05__  \n",
      "                   /                        \\                                /                        \\ \n",
      "                 c: 1                _f: 1, t: 3.1__                  _f: 0, t: 6.5__               c: 2\n",
      "                                    /               \\                /               \\                  \n",
      "                                  c: 2            c: 1             c: 2            c: 1                 \n"
     ]
    }
   ],
   "source": [
    "# f = feature index, t = decision threshold, c = class index\n",
    "dtc.print_tree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
